{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import dataset\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Configs\n",
    "config = json.load(open(\"config.json\")) \n",
    "ds_config = config['dataset']\n",
    "hyper_params = config['hyper_params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Create AMASS DS object\n",
    "amass = dataset.AMASS(\n",
    "\tds_config['amass_path'], \n",
    "\twhitelist=ds_config['whitelist'], \n",
    "\tmodel_path=ds_config['model_filepath'],\n",
    "\tframerate_adjust=ds_config['framerate_adjust']\n",
    "\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m0(beta, z_dim, res_num, J_tree, activation=None):\n",
    "\t# 0. full body\n",
    "\tinp = keras.layers.Input((22, 4, 4))\n",
    "\tenc = models.StaticEncoder(res_num, z_dim, activation)\n",
    "\tdec = models.Decoder(res_num, activation=activation)\n",
    "\tvae = models.VAE(enc, dec, beta, J_tree, 1)\n",
    "\treturn dec, vae\n",
    "\n",
    "def m1(beta, z_dim, res_num, J_tree, activation=None):\n",
    "\t# 1. hh\n",
    "\tinp = keras.layers.Input((3, 4, 4))\n",
    "\tenc = models.StaticEncoder(res_num, z_dim, activation)\n",
    "\tdec = models.Decoder(res_num, activation=activation)\n",
    "\tvae = models.VAE(enc, dec, beta, J_tree, 1)\n",
    "\treturn vae\n",
    "\n",
    "def m2(beta, z_dim, res_num, J_tree, activation=None):\n",
    "\t# 1. hh\n",
    "\tinp = keras.layers.Input((16, 3, 4, 4))\n",
    "\tenc = models.SequenceEncoder(16, res_num, z_dim, activation=activation)\n",
    "\tdec = models.Decoder(res_num, activation=activation)\n",
    "\tvae = models.VAE(enc, dec, beta, J_tree, 1)\n",
    "\treturn vae\n",
    "\n",
    "def m3(beta, z_dim, res_num, J_tree, trained_dec, activation=None):\n",
    "\t# 1. hh\n",
    "\tinp = keras.layers.Input((3, 4, 4))\n",
    "\tenc = models.StaticEncoder(res_num, z_dim, activation)\n",
    "\tdec = trained_dec\n",
    "\tdec.trainable = False\n",
    "\tvae = models.VAE(enc, dec, beta, J_tree, 2)\n",
    "\treturn vae\n",
    "\n",
    "def m4(beta, z_dim, res_num, J_tree, trained_dec, activation=None):\n",
    "\t# 1. hh\n",
    "\tinp = keras.layers.Input((16, 3, 4, 4))\n",
    "\tenc = models.SequenceEncoder(16, res_num, z_dim, activation=activation)\n",
    "\tdec = trained_dec\n",
    "\tdec.trainable = False\n",
    "\tvae = models.VAE(enc, dec, beta, J_tree, 2)\n",
    "\treturn vae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = np.load(ds_config['model_filepath'])\n",
    "J_tree = model['kintree_table']\n",
    "\n",
    "def _train(vae:keras.Model, tr, te, batch_size, epoch_num, callbacks=None):\n",
    "\tvae.compile(loss=models.build_reconstruction_error(J_tree))\n",
    "\treturn vae.fit(\n",
    "\t\ttf.data.Dataset.zip(tr).batch(batch_size),\n",
    "\t\tvalidation_data=tf.data.Dataset.zip(te).batch(batch_size),\n",
    "\t\tepochs=epoch_num, callbacks=callbacks,\n",
    "\t)\n",
    "\n",
    "def train(hparams, batch_size, epochs, callbacks=[]):\n",
    "\tsave_dir = lambda s: f'{hparams[HP_BETA]}_{hparams[HP_Z_DIMS]}_{hparams[HP_RES_NUM]}/{s}'\n",
    "\tcallbacks = callbacks + [\n",
    "\t\tkeras.callbacks.TerminateOnNaN(),\n",
    "\t\tkeras.callbacks.EarlyStopping(patience=20),\n",
    "\t\tkeras.callbacks.ReduceLROnPlateau(),\n",
    "\t]\n",
    "\tcb = lambda s: callbacks + [\n",
    "\t\tkeras.callbacks.TensorBoard('logs/fit/'+save_dir(s), histogram_freq=10, write_images=True),\n",
    "\t\tkeras.callbacks.ModelCheckpoint('saved_models/'+save_dir(s), save_best_only=True, save_weights_only=True),\n",
    "\t\thp.KerasCallback('logs/hp_tuning/'+save_dir(s), hparams)\n",
    "\t]\n",
    "\n",
    "\ttr, te = amass.get_fullbody()\n",
    "\tdec, v0 = m0(hparams[HP_BETA], hparams[HP_Z_DIMS], hparams[HP_RES_NUM], J_tree)\n",
    "\t_train(v0, tr, te, batch_size, epochs, cb('full_body'))\n",
    "\n",
    "\ttr, te = amass.get_hh()\n",
    "\tv1 = m1(hparams[HP_BETA], hparams[HP_Z_DIMS], hparams[HP_RES_NUM], J_tree)\n",
    "\t_train(v1, tr, te, batch_size, epochs, cb('hh_static'))\n",
    "\n",
    "\ttr, te = amass.get_hh_sequence()\n",
    "\tv2 = m2(hparams[HP_BETA], hparams[HP_Z_DIMS], hparams[HP_RES_NUM], J_tree)\n",
    "\t_train(v2, tr, te, batch_size, epochs, cb('hh_sequence'))\n",
    "\n",
    "\ttr, te = amass.get_hh()\n",
    "\tv3 = m3(hparams[HP_BETA], hparams[HP_Z_DIMS], hparams[HP_RES_NUM], J_tree, dec)\n",
    "\t_train(v3, tr, te, batch_size, epochs, cb('hh_static_pre'))\n",
    "\n",
    "\ttr, te = amass.get_hh_sequence()\n",
    "\tv4 = m4(hparams[HP_BETA], hparams[HP_Z_DIMS], hparams[HP_RES_NUM], J_tree, dec)\n",
    "\t_train(v4, tr, te, batch_size, epochs, cb('hh_sequence'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.parse import urlparse, urlunparse\n",
    "\n",
    "HP_BETA = hp.HParam('beta', hp.Discrete(hyper_params['beta']))\n",
    "HP_Z_DIMS = hp.HParam('z_dims', hp.Discrete(hyper_params['z_dims']))\n",
    "HP_RES_NUM = hp.HParam('res_num', hp.Discrete(hyper_params['res_num']))\n",
    "\n",
    "session_num = 0\n",
    "\n",
    "discord_webhook = os.environ.get('PTFB_TRAIN_MONITOR_URL_DISCORD')\n",
    "callbacks = []\n",
    "if discord_webhook:\n",
    "\turl = urlparse(discord_webhook)\n",
    "\tcallbacks = callbacks + keras.callbacks.RemoteMonitor(\n",
    "\t\turlunparse(url._replace(path='')), url.path,\n",
    "\t\tfield='content', send_as_json=True\n",
    "\t)\n",
    "\n",
    "# make ds small for visualize purpose\n",
    "amass.ds = amass.ds[:1]\n",
    "amass.ds[0] = amass.ds[0].take(40)\n",
    "\n",
    "for beta in HP_BETA.domain.values:\n",
    "\tfor z_dims in HP_Z_DIMS.domain.values:\n",
    "\t\tfor res_num in HP_RES_NUM.domain.values:\n",
    "\t\t\thparams = {\n",
    "\t\t\t\t\tHP_BETA: beta,\n",
    "\t\t\t\t\tHP_Z_DIMS: z_dims,\n",
    "\t\t\t\t\tHP_RES_NUM: res_num,\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\trun_name = \"run-%d\" % session_num\n",
    "\t\t\tprint('--- Starting trial: %s' % run_name)\n",
    "\t\t\tprint({h.name: hparams[h] for h in hparams})\n",
    "\t\t\ttrain(hparams, 32, 100, callbacks)\n",
    "\t\t\tsession_num += 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "280ff61a060d037031b217065608a23d1fb5b53ee7368e5f4b8c0084076cb6b6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
